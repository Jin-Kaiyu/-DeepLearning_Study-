"""
ä½¿ç”¨Faster R-CNNè®­ç»ƒPASCAL VOCç›®æ ‡æ£€æµ‹ä»»åŠ¡

ä½œè€…: DeepLearning_Study
æ—¥æœŸ: 2025å¹´9æœˆ
è¯¾ç¨‹: å·¥ä¸šè¡¨é¢åˆ’ç—•æ£€æµ‹ç ”ç©¶ - ç¬¬5å‘¨
"""

import os
from collections import defaultdict
import torch
import torchvision
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
from torchvision.ops import box_iou
import torch.optim as optim
import time
import numpy as np
from datetime import datetime
from voc_detection_dataset import VOCDetectionDataset, create_voc_data_loaders

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")


def create_faster_rcnn_model(num_classes: int, pretrained: bool = True):
    """
    åˆ›å»ºFaster R-CNNæ¨¡å‹
    
    Args:
        num_classes: ç±»åˆ«æ•°é‡ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        
    Returns:
        Faster R-CNNæ¨¡å‹
    """
    if pretrained:
        # ä½¿ç”¨torchvisioné¢„è®­ç»ƒçš„Faster R-CNN (ä¿®å¤deprecatedè­¦å‘Š)
        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')
        
        # æ›¿æ¢åˆ†ç±»å¤´ä»¥é€‚åº”VOCçš„ç±»åˆ«æ•°
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(
            in_features, num_classes)
    else:
        # ä»å¤´å¼€å§‹è®­ç»ƒ
        backbone = torchvision.models.mobilenet_v2(pretrained=False).features
        backbone.out_channels = 1280
        
        anchor_generator = AnchorGenerator(
            sizes=((32, 64, 128, 256, 512),),
            aspect_ratios=((0.5, 1.0, 2.0),)
        )
        
        roi_pooler = torchvision.ops.MultiScaleRoIAlign(
            featmap_names=['0'],
            output_size=7,
            sampling_ratio=2
        )
        
        model = FasterRCNN(
            backbone,
            num_classes=num_classes,
            rpn_anchor_generator=anchor_generator,
            box_roi_pool=roi_pooler
        )
    
    return model


def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    """
    model.train()
    total_loss = 0
    loss_classifier = 0
    loss_box_reg = 0
    loss_objectness = 0
    loss_rpn_box_reg = 0
    
    start_time = time.time()
    
    for i, (images, targets) in enumerate(data_loader):
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        
        # å‰å‘ä¼ æ’­
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()
        
        # è®°å½•æŸå¤±
        total_loss += losses.item()
        loss_classifier += loss_dict.get('loss_classifier', 0).item()
        loss_box_reg += loss_dict.get('loss_box_reg', 0).item()
        loss_objectness += loss_dict.get('loss_objectness', 0).item()
        loss_rpn_box_reg += loss_dict.get('loss_rpn_box_reg', 0).item()
        
        if i % print_freq == 0:
            elapsed_time = time.time() - start_time
            print(f'Epoch: [{epoch}][{i}/{len(data_loader)}] '
                  f'Loss: {losses.item():.4f} '
                  f'Time: {elapsed_time:.2f}s')
            start_time = time.time()
    
    # è®¡ç®—å¹³å‡æŸå¤±
    num_batches = len(data_loader)
    avg_loss = total_loss / num_batches
    avg_loss_classifier = loss_classifier / num_batches
    avg_loss_box_reg = loss_box_reg / num_batches
    avg_loss_objectness = loss_objectness / num_batches
    avg_loss_rpn_box_reg = loss_rpn_box_reg / num_batches
    
    return {
        'total_loss': avg_loss,
        'loss_classifier': avg_loss_classifier,
        'loss_box_reg': avg_loss_box_reg,
        'loss_objectness': avg_loss_objectness,
        'loss_rpn_box_reg': avg_loss_rpn_box_reg
    }



@torch.no_grad()
def evaluate(model, data_loader, device, iou_threshold: float = 0.5):
    """åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹å¹¶è®¡ç®—VOCé£æ ¼çš„mAP (IoU=0.5)."""
    model.eval()
    all_detections = []
    all_ground_truths = []

    for images, targets in data_loader:
        images = [img.to(device) for img in images]
        outputs = model(images)

        outputs_cpu = [{k: v.detach().cpu() for k, v in output.items()} for output in outputs]
        targets_cpu = [{k: (v.detach().cpu() if torch.is_tensor(v) else v) for k, v in target.items()} for target in targets]

        all_detections.extend(outputs_cpu)
        all_ground_truths.extend(targets_cpu)

    class_names = getattr(data_loader.dataset, 'CLASSES', None)
    map_value, per_class_ap = calculate_map(all_detections, all_ground_truths, class_names=class_names, iou_threshold=iou_threshold)

    if per_class_ap and class_names:
        print("éªŒè¯é›†AP (IoU=0.5):")
        for class_id, ap in sorted(per_class_ap.items()):
            if class_id == 0:
                continue
            name = class_names[class_id - 1] if 1 <= class_id <= len(class_names) else str(class_id)
            print(f"  {name:<15}: {ap:.4f}")

    return map_value


def calculate_map(detections, ground_truths, class_names=None, iou_threshold: float = 0.5):
    """æ ¹æ®æ£€æµ‹ç»“æœå’Œæ ‡æ³¨è®¡ç®—mAPåŠæ¯ç±»AP."""
    per_class_stats = defaultdict(lambda: {"scores": [], "matches": [], "num_gt": 0})

    for det, gt in zip(detections, ground_truths):
        gt_boxes = gt.get('boxes')
        gt_labels = gt.get('labels')
        if gt_boxes is None or gt_labels is None:
            continue

        if torch.is_tensor(gt_boxes):
            gt_boxes = gt_boxes.cpu()
        if torch.is_tensor(gt_labels):
            gt_labels = gt_labels.cpu()

        for label in gt_labels.tolist():
            if label == 0:
                continue
            per_class_stats[label]["num_gt"] += 1

        matched = defaultdict(set)

        if len(det.get('boxes', [])) == 0:
            continue

        pred_boxes = det['boxes']
        pred_labels = det['labels']
        pred_scores = det['scores']

        if torch.is_tensor(pred_boxes):
            pred_boxes = pred_boxes.cpu()
        if torch.is_tensor(pred_labels):
            pred_labels = pred_labels.cpu()
        if torch.is_tensor(pred_scores):
            pred_scores = pred_scores.cpu()

        order = torch.argsort(pred_scores, descending=True)
        pred_boxes = pred_boxes[order]
        pred_labels = pred_labels[order]
        pred_scores = pred_scores[order]

        for box, label, score in zip(pred_boxes, pred_labels, pred_scores):
            label = int(label.item()) if hasattr(label, 'item') else int(label)
            if label == 0:
                continue
            score = float(score.item()) if hasattr(score, 'item') else float(score)
            per_class_stats[label]["scores"].append(score)

            candidate_indices = torch.where(gt_labels == label)[0]
            if len(candidate_indices) == 0:
                per_class_stats[label]["matches"].append(0)
                continue

            ious = box_iou(box.unsqueeze(0), gt_boxes[candidate_indices]).squeeze(0)
            best_iou, best_idx = torch.max(ious, dim=0)
            gt_index = candidate_indices[best_idx].item()

            if best_iou >= iou_threshold and gt_index not in matched[label]:
                per_class_stats[label]["matches"].append(1)
                matched[label].add(gt_index)
            else:
                per_class_stats[label]["matches"].append(0)

    ap_per_class = {}
    for label, stats in per_class_stats.items():
        num_gt = stats["num_gt"]
        if num_gt == 0:
            continue

        scores = np.array(stats["scores"], dtype=np.float32)
        matches = np.array(stats["matches"], dtype=np.float32)

        if scores.size == 0:
            ap_per_class[label] = 0.0
            continue

        order = np.argsort(-scores)
        matches = matches[order]

        tps = matches
        fps = 1.0 - matches

        cum_tp = np.cumsum(tps)
        cum_fp = np.cumsum(fps)

        recalls = cum_tp / max(num_gt, 1)
        precisions = cum_tp / np.maximum(cum_tp + cum_fp, 1e-12)

        ap = 0.0
        for recall_threshold in np.linspace(0.0, 1.0, 11):
            precisions_at_recall = precisions[recalls >= recall_threshold]
            precision = np.max(precisions_at_recall) if precisions_at_recall.size > 0 else 0.0
            ap += precision
        ap /= 11.0

        ap_per_class[label] = float(ap)

    if ap_per_class:
        map_value = float(np.mean(list(ap_per_class.values())))
    else:
        map_value = 0.0

    return map_value, ap_per_class



def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è¶…å‚æ•°
    num_epochs = 10
    batch_size = 4  # å¢å¤§batch sizeæé«˜è®­ç»ƒæ•ˆç‡
    learning_rate = 0.005
    num_classes = 21  # VOCçš„20ä¸ªç±»åˆ« + èƒŒæ™¯
    
    # æ•°æ®è·¯å¾„
    root_dir = "/data/wf/Conference_paper_guidance/Codes/Kayu J/VOC2012"  # æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒFaster R-CNN on VOC...")
    print(f"è¶…å‚æ•°: epochs={num_epochs}, batch_size={batch_size}, lr={learning_rate}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = create_voc_data_loaders(
        root_dir, batch_size=batch_size, num_workers=4)
    
    print(f"è®­ç»ƒé›†æ‰¹æ¬¡: {len(train_loader)}")
    print(f"éªŒè¯é›†æ‰¹æ¬¡: {len(val_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_faster_rcnn_model(num_classes, pretrained=True)
    model.to(device)
    
    # ä¼˜åŒ–å™¨
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.0005)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)
    
    # è®­ç»ƒå†å²è®°å½•
    history = {
        'train_loss': [],
        'val_map': [],
        'learning_rates': []
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs('checkpoints', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    
    print("ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    
    for epoch in range(num_epochs):
        print(f"\n=== Epoch {epoch + 1}/{num_epochs} ===")
        
        # è®­ç»ƒä¸€ä¸ªepoch
        train_metrics = train_one_epoch(model, optimizer, train_loader, device, epoch)
        
        # æ›´æ–°å­¦ä¹ ç‡
        lr_scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        # è¯„ä¼°
        val_map = evaluate(model, val_loader, device)
        
        # è®°å½•å†å²
        history['train_loss'].append(train_metrics['total_loss'])
        history['val_map'].append(val_map)
        history['learning_rates'].append(current_lr)
        
        # æ‰“å°è¿›åº¦
        print(f"Epoch {epoch + 1}ç»“æœ:")
        print(f"  è®­ç»ƒæŸå¤±: {train_metrics['total_loss']:.4f}")
        print(f"  éªŒè¯mAP: {val_map:.4f}")
        print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")
        print(f"  åˆ†ç±»æŸå¤±: {train_metrics['loss_classifier']:.4f}")
        print(f"  å›å½’æŸå¤±: {train_metrics['loss_box_reg']:.4f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 2 == 0:
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'lr_scheduler_state_dict': lr_scheduler.state_dict(),
                'history': history
            }
            checkpoint_path = f'checkpoints/faster_rcnn_epoch_{epoch + 1}.pth'
            torch.save(checkpoint, checkpoint_path)
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = 'checkpoints/faster_rcnn_final.pth'
    torch.save(model.state_dict(), final_model_path)
    print(f"âœ… è®­ç»ƒå®Œæˆ! æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\nğŸ¯ æœ€ç»ˆç»“æœ:")
    print(f"æœ€ä½³è®­ç»ƒæŸå¤±: {min(history['train_loss']):.4f}")
    print(f"æœ€ä½³éªŒè¯mAP: {max(history['val_map']):.4f}")
    
    return model, history


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        model, history = main()
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = 'logs/training_history.npy'
        np.save(history_path, history)
        print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()